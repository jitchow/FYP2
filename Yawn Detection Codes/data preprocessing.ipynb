{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932ff78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import face_utils\n",
    "import numpy as np\n",
    "import argparse\n",
    "import imutils\n",
    "import dlib\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a5a8d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face_yawn(folder, label):\n",
    "    IMG_SIZE = 145\n",
    "    data = []\n",
    "    \n",
    "    for image in os.listdir(folder):\n",
    "        image_array = cv2.imread(os.path.join(folder, image), cv2.IMREAD_COLOR)\n",
    "        face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "        faces = face_cascade.detectMultiScale(image_array, 1.3, 5)\n",
    "        for (x, y, w, h) in faces:\n",
    "            img = cv2.rectangle(image_array, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "            roi_color = img[y:y+h, x:x+w]\n",
    "            resized_array = cv2.resize(roi_color, (IMG_SIZE, IMG_SIZE))\n",
    "            cv2.imwrite(folder + '_mouth/' + image, resized_array)\n",
    "            data.append([resized_array, label])\n",
    "    \n",
    "    return data;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6fc6100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_face_yawn_dlib(folder, label):\n",
    "    IMG_SIZE = 80\n",
    "    data = []\n",
    "    \n",
    "    for image in os.listdir(folder):\n",
    "        try:\n",
    "            image_array = cv2.imread(os.path.join(folder, image), cv2.IMREAD_COLOR)\n",
    "            gray = cv2.cvtColor(image_array, cv2.COLOR_BGR2GRAY)\n",
    "            rects = detector(gray, 1)\n",
    "            for (i, rect) in enumerate(rects):\n",
    "                shape = predictor(gray, rect)\n",
    "                shape = face_utils.shape_to_np(shape)\n",
    "\n",
    "                (x, y, w, h) = face_utils.rect_to_bb(rect)\n",
    "                roi = image_array[y:y+h, x:x+w]\n",
    "                resized_array = cv2.resize(roi, (IMG_SIZE, IMG_SIZE))\n",
    "                cv2.imwrite(folder + '_face/' + image, resized_array)\n",
    "                data.append([resized_array, label])\n",
    "        except:\n",
    "            continue\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ea596d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "yawn_folders = ['no_yawn', 'yawn']\n",
    "\n",
    "no_yawn = crop_face_yawn_dlib('kaggle_dataset/' + yawn_folders[0], 0)\n",
    "yawn = crop_face_yawn_dlib('kaggle_dataset/' + yawn_folders[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6f291574",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "510"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(yawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "846c4f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "yawn_folders = ['no_yawn', 'yawn']\n",
    "\n",
    "no_yawn = crop_face_yawn('kaggle_dataset/' + yawn_folders[0], 0)\n",
    "yawn = crop_face_yawn('kaggle_dataset/' + yawn_folders[1], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98763819",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_yawn = no_yawn + yawn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0e3bb79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for features, label in combined_yawn:\n",
    "    X.append(features)\n",
    "    y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c95333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).reshape(-1, 145, 145, 3)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c8cc1ed5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d17a5e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_idg = ImageDataGenerator(rescale=1/255, zoom_range=0.2, horizontal_flip=True, rotation_range=30)\n",
    "test_idg = ImageDataGenerator(rescale=1/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a07ff15",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generated = train_idg.flow(np.array(X_train), y_train, shuffle=False)\n",
    "test_generated = test_idg.flow(np.array(X_test), y_test, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "60da4471",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_generated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "acd80d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ed8472d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 143, 143, 256)     7168      \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 71, 71, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 69, 69, 128)       295040    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 34, 34, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        73792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 14, 14, 32)        18464     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 7, 7, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1568)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 64)                100416    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4)                 260       \n",
      "=================================================================\n",
      "Total params: 495,140\n",
      "Trainable params: 495,140\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), activation=\"relu\", input_shape=X_train.shape[1:]))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
    "model.add(MaxPooling2D(2, 2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Dense(64, activation=\"relu\"))\n",
    "model.add(Dense(4, activation=\"softmax\"))\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], optimizer=\"adam\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c4c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_generator, epochs=300, validation_data=test_generator, shuffle=True, validation_steps=len(test_generator))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
